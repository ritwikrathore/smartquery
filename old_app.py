# app.py

import os
import json
import base64
from datetime import datetime
from pathlib import Path
import io
import time
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import streamlit as st
import sqlite3
from typing import Dict, List, Union, Optional, Literal, Any, AsyncGenerator, Tuple
import asyncio
import logging
from pydantic import BaseModel, Field
from pydantic_ai import Agent, RunContext, ModelRetry
from pydantic_ai.usage import Usage, UsageLimits
from pydantic_ai.models.gemini import GeminiModel
from pydantic_ai.format_as_xml import format_as_xml
import plotly.express as px
import nest_asyncio

def run_async(coro):
    """Runs an async coroutine reliably in the current Streamlit event loop."""
    try:
        loop = asyncio.get_running_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        nest_asyncio.apply(loop)
    return loop.run_until_complete(coro)

# Apply nest_asyncio at the start to allow nested event loops if needed
# This doesn't fix the core issue but helps in some edge cases
nest_asyncio.apply()

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
logger.info("nest_asyncio applied at startup.")
# logger.setLevel(logging.DEBUG) # Uncomment for detailed debugging

# --- Google Generative AI Import ---
try:
    import google.generativeai as genai
except ImportError:
    st.error("Google Generative AI SDK not installed. Please run `pip install google-generativeai`.")
    st.stop()

# Set up logging
logging.basicConfig(level=logging.INFO) # Adjusted level for production
logger = logging.getLogger(__name__) # Use __name__ for module-level logger
# logger.setLevel(logging.DEBUG) # Uncomment for detailed debugging


# --- Configuration and Dependencies (Moved from config.py) ---

# Default SQLite database path (ensure this file exists or is created)
DEFAULT_DB_PATH = st.secrets.get("DATABASE_PATH", "assets/data1.sqlite")

class AgentDependencies:
    """Manages dependencies like database connections."""
    def __init__(self):
        self.db_connection: Optional[sqlite3.Connection] = None

    @classmethod
    def create(cls) -> 'AgentDependencies':
        return cls()

    def with_db(self, db_path: str = DEFAULT_DB_PATH) -> 'AgentDependencies':
        """Establishes SQLite connection."""
        try:
            self.db_connection = sqlite3.connect(db_path)
            logger.info(f"Successfully connected to database: {db_path}")
        except sqlite3.Error as e:
            logger.error(f"Error connecting to database {db_path}: {e}")
            st.error(f"Failed to connect to the database: {e}")
            self.db_connection = None # Ensure connection is None if failed
        return self

    async def cleanup(self):
        """Closes database connection."""
        if self.db_connection:
            self.db_connection.close()
            logger.info("Database connection closed.")

# Define Token Usage Limits for Gemini
# Instead of trying to initialize UsageLimits with parameters, create a simple object
# Initialize the class directly - assumes it takes no arguments or has defaults
DEFAULT_USAGE_LIMITS = UsageLimits()
# Remove setattr calls - limits are often handled during run
# setattr(DEFAULT_USAGE_LIMITS, 'request_limit', 500) # Removed
# setattr(DEFAULT_USAGE_LIMITS, 'total_tokens_limit', 1000000) # Removed


# --- Pydantic Models for API Structure ---

class SQLQueryResult(BaseModel):
    """Response when SQL could be successfully generated"""
    sql_query: str = Field(..., description="The SQL query to execute")
    explanation: str = Field("", description="Explanation of what the SQL query does")

class PythonCodeResult(BaseModel):
    """Response when Python code needs to be executed for analysis or visualization"""
    python_code: str = Field(..., description="The Python code to execute using pandas (df) and matplotlib (plt)")
    explanation: str = Field("", description="Explanation of what the Python code does")

class InvalidRequest(BaseModel):
    """Response when the request cannot be processed"""
    error_message: str = Field(..., description="Error message explaining why the request is invalid")

# Place these near your other Pydantic models (e.g., after QueryResponse)

class SuggestedTables(BaseModel):
    """Lists tables suggested by the TableAgent."""
    table_names: List[str] = Field(..., description="List of table names deemed relevant to the user query.")
    reasoning: str = Field(..., description="Brief explanation for selecting these tables.")

class PrunedSchemaResult(BaseModel):
    """Contains the pruned schema string generated by the ColumnPruneAgent."""
    pruned_schema_string: str = Field(..., description="The database schema string containing only essential columns for the query.")
    explanation: str = Field(..., description="Explanation of which columns were kept and why.")


class QueryResponse(BaseModel):
    """Complete response from the agent, potentially including text, SQL, and Python code"""
    text_message: str = Field(..., description="Human-readable response explaining the action or findings")
    sql_result: Optional[SQLQueryResult] = Field(None, description="SQL query details if SQL was generated")
    python_result: Optional[PythonCodeResult] = Field(None, description="Python code details if Python was generated for visualization/analysis")

# --- NEW: Pydantic Model for Database Classification ---
class DatabaseClassification(BaseModel):
    """Identifies the target database for a user query."""
    database_key: Literal["IFC", "MIGA", "UNKNOWN"] = Field(..., description="The database key ('IFC', 'MIGA') the user query most likely refers to, based on keywords and the database descriptions provided. Use 'UNKNOWN' if the query is ambiguous, unrelated, or a general greeting/request.")
    reasoning: str = Field(..., description="Brief explanation for the classification (e.g., 'Query mentions IFC investments', 'Query mentions MIGA guarantees', 'Query is ambiguous/general').")

# --- Configure Google Gemini ---
try:
    # Load API key from Streamlit secrets instead of environment variable
    google_api_key = st.secrets.get("GOOGLE_API_KEY", os.getenv("GOOGLE_API_KEY"))
    if not google_api_key:
        st.error("🔴 GOOGLE_API_KEY not found in secrets.toml or environment variables!")
        st.stop()

    # Configure the Google Generative AI SDK - REMOVED FROM HERE
    # genai.configure(api_key=google_api_key)
    # logger.info("Google Generative AI SDK configured.")

    # Initialize Gemini Model using pydantic_ai
    gemini_model_name = st.secrets.get("GEMINI_MODEL", "gemini-2.0-flash")
    
    # Initialize the model according to pydantic_ai documentation
    # Remove api_key argument - it should use env vars/secrets automatically
    llm = GeminiModel(
        model_name=gemini_model_name
    )
    logger.info(f"Using Gemini Model via pydantic_ai: {gemini_model_name}")

except Exception as e:
    logger.error(f"Error configuring Google Gemini: {e}")
    st.error(f"Error configuring Google Gemini: {e}")
    st.stop()

# --- Define the Agents ---

# --- NEW: Table Selection Agent Blueprint ---
def create_table_selection_agent(model_instance: GeminiModel) -> Agent:
    return Agent(
        model_instance,
        result_type=SuggestedTables,
        name="Table Selection Agent",
        retries=2, # Lower retries for potentially simpler task
        system_prompt="""You are an expert database assistant. Your task is to analyze a user's query and a list of available tables (with descriptions) in a specific database.
Identify the **minimum set of table names** from the provided list that are absolutely required to answer the user's query.
Consider the table names and their descriptions carefully.
Output ONLY the list of relevant table names and a brief reasoning."""
    )

# --- NEW: Column Pruning Agent Blueprint ---
def create_column_prune_agent(model_instance: GeminiModel) -> Agent:
    return Agent(
        model_instance,
        result_type=PrunedSchemaResult,
        name="Column Pruning Agent",
        retries=2,
        system_prompt="""You are an expert database assistant optimizing schemas for LLM query generation.
You will receive a user query and the FULL schemas (table name, columns with types and descriptions) for tables deemed relevant to that query.
Your task is to **prune these schemas** by removing columns that are **NOT essential** for answering the specific user query.
Focus on keeping primary keys, foreign keys involved in potential joins, columns mentioned directly or implicitly in the query (e.g., for filtering, aggregation, or selection), and columns needed for context.
Format the output as a string containing the pruned schemas, maintaining a similar structure to the input (Table: ..., Columns: ...), but listing ONLY the essential columns for each table. Provide a brief explanation of your pruning choices."""
    )

# --- Query Agent Blueprint --- #
def create_query_agent(model_instance: GeminiModel) -> Agent:
    agent_instance = Agent(
        model_instance,
        deps_type=AgentDependencies,
        result_type=QueryResponse,
        name="SQL and Visualization Assistant",
        retries=3,
    )

    # --- Re-apply decorators using the agent_instance --- #
    @agent_instance.system_prompt
    def local_generate_system_prompt() -> str:
        return generate_system_prompt() # Call the global prompt generator function

    @agent_instance.tool
    async def local_execute_sql(ctx: RunContext[AgentDependencies], query: str) -> Union[List[Dict], str]:
        # This just calls the global execute_sql function definition
        return await execute_sql(ctx, query)

    @agent_instance.result_validator
    async def local_validate_query_result(ctx: RunContext[AgentDependencies], result: QueryResponse) -> QueryResponse:
        return await validate_query_result(ctx, result)

    return agent_instance

# --- NEW: System Prompt using Decorator --- #

def generate_system_prompt() -> str:
    """Generates the system prompt for the data analysis agent."""
    prompt = f"""You are an expert data analyst assistant. Your role is to help users query and analyze data from a SQLite database.

IMPORTANT: The database schema will be included at the beginning of each user message. Use this schema information to understand the database structure and generate accurate SQL queries. DO NOT respond that you need to know the table structure - it is already provided in the message.

CRITICAL RULES FOR SQL GENERATION:
1. For ANY question about data in the database (counts, totals, listings, comparisons, etc.), you MUST generate an appropriate SQLite query.
2. PAY ATTENTION TO COLUMN NAMES: If a column name in the provided schema contains spaces or special characters, you MUST enclose it in double quotes (e.g., SELECT "Total IFC Investment Amount" FROM ...). Failure to quote such names will cause errors.
3. AGGREGATIONS: For questions asking about totals, sums, or aggregations, use SQL aggregate functions (SUM, COUNT, AVG, etc.).
4. GROUPING: When a question mentions "per" some field (e.g., "per product line"), this requires a GROUP BY clause for that field.
5. SUM FOR TOTALS: Numerical fields asking for totals must use SUM() in your query.
6. SECURITY: ONLY generate SELECT queries. NEVER generate SQL statements that modify the database (INSERT, UPDATE, DELETE, DROP, ALTER, CREATE, TRUNCATE, etc.) or could be potentially harmful. These will be blocked by the system for security reasons and will cause errors.

PYTHON CODE FOR DATA PREPARATION (NOT PLOTTING):
- If a user requests analysis or visualization that requires data manipulation *after* the SQL query (e.g., complex calculations, reshaping data, setting index for charts), generate Python code using pandas.
- Assume the SQL results are available in a pandas DataFrame named 'df'.
- The Python code should ONLY perform data manipulation/preparation on the 'df'.
- CRITICAL: DO NOT include any plotting code (e.g., `matplotlib`, `seaborn`, `st.pyplot`) in the Python code block. The final plotting using native Streamlit charts (like `st.bar_chart`) will be handled separately by the application based on your textual explanation and the prepared data.
- If no specific Python data manipulation is needed beyond the SQL query, do not generate a Python code result.

VISUALIZATION REQUESTS:
- When users request charts, graphs, or plots, first generate the necessary SQL query.
- If the data from SQL needs further processing for the chart (e.g., setting the index, renaming columns), generate Python code as described above to prepare the 'df'.
- In your text response, clearly state the type of chart you recommend (e.g., "bar chart", "line chart", "pie chart", "scatter plot") based on the user's request and the data structure. Use these exact phrases where possible.
- NEVER respond that you cannot create visualizations.

RESPONSE STRUCTURE:
1. First, review the database schema provided in the message.
2. Understand the request: Does it require data retrieval (SQL), potential data preparation (Python), or just a textual answer?
3. Generate SQL: If data is needed, generate an accurate SQLite query string following the rules above, suitable for the `sql_result` field in the response.
4. Generate Python Data Prep Code (if needed): If data manipulation beyond SQL is required for analysis or the requested chart, generate Python pandas code acting on 'df'.
5. Explain Clearly: Explain the SQL query and any Python data preparation steps. If visualization was requested, explicitly suggest the chart type (e.g., "bar chart", "line chart") in your text message.
6. Format Output: Format your final response using the 'QueryResponse' structure. Include 'text_message', 'sql_result' (if applicable), and 'python_result' (if Python data prep code was generated).
7. **CRUCIAL**: Even if you use internal tools (like `execute_sql`) to find the answer or validate the query during your thought process, the final `QueryResponse` object you return MUST contain the generated SQL query string in the `sql_result` field if the user's request required data retrieval from the database. Do not omit the `sql_result` just because you used a tool internally.
8. Safety: Focus ONLY on SELECT queries. Do not generate SQL/Python that modifies the database.
9. Efficiency: Write efficient SQL queries.

Remember, your final output must be the structured 'QueryResponse' object containing the text message and the generated SQL/Python strings (if applicable).
"""
    return prompt

# --- Define Agent Tools ---

async def execute_sql(ctx: RunContext[AgentDependencies], query: str) -> Union[List[Dict], str]:
    """
    Executes a given SQLite SELECT query and returns the results.
    IMPORTANT: Your primary goal is usually to generate the SQL query string for the final 'QueryResponse' structure, not to execute it yourself.
    Only use this tool if you absolutely need to fetch intermediate data during your reasoning process to answer a complex multi-step question.
    **Using this tool DOES NOT replace the requirement to include the SQL query string in the `sql_result` field of the final `QueryResponse` object if the original request required data retrieval.**
    Args:
        query (str): The SQLite SELECT query to execute.
    Returns:
        List[Dict]: A list of dictionaries representing the query results.
        str: An error message if the query fails or is not a SELECT statement.
    """
    if not ctx.deps.db_connection:
        return "Error: Database connection is not available."
    
    # Enhanced safety checks: whitelist approach - only allow SELECT statements
    query = query.strip()
    
    # Check for SQL commands that could modify the database or compromise security
    forbidden_commands = ['ALTER', 'CREATE', 'DELETE', 'DROP', 'INSERT', 'UPDATE', 'PRAGMA', 
                          'ATTACH', 'DETACH', 'VACUUM', 'GRANT', 'REVOKE', 'EXECUTE', 'TRUNCATE']
    
    # Normalized query for checking (uppercase without comments)
    normalized_query = ' '.join([
        line for line in query.upper().split('\n') 
        if not line.strip().startswith('--')
    ])
    
    # Basic safety check: only allow SELECT statements
    if not normalized_query.startswith("SELECT"):
        logger.warning(f"Attempted non-SELECT query execution: {query}")
        return "Error: Only SELECT queries are allowed."
    
    # Check for forbidden commands that might be hidden in subqueries or clauses
    for cmd in forbidden_commands:
        if f" {cmd} " in f" {normalized_query} ":
            logger.warning(f"Blocked query containing forbidden command '{cmd}': {query}")
            return f"Error: Detected potentially harmful SQL command '{cmd}'. For security reasons, this operation is not allowed."
    
    # Check for multiple statements with semicolons (except those in quotes)
    # Simple check - this isn't perfect but adds another layer of protection
    statement_count = 0
    in_quotes = False
    for char in query:
        if char in ["'", '"']:
            in_quotes = not in_quotes
        if char == ';' and not in_quotes:
            statement_count += 1
    
    if statement_count > 0:
        logger.warning(f"Blocked query with multiple statements: {query}")
        return "Error: Multiple SQL statements are not allowed for security reasons."
    
    try:
        cursor = ctx.deps.db_connection.cursor()
        cursor.execute(query)
        columns = [description[0] for description in cursor.description] if cursor.description else []
        results = cursor.fetchall()
        logger.info(f"Executed SQL query successfully. Rows returned: {len(results)}")
        return [dict(zip(columns, row)) for row in results]
    except sqlite3.Error as e:
        logger.error(f"SQL execution error: {e}. Query: {query}")
        return f"Error executing SQL query: {str(e)}"
    except Exception as e:
        logger.error(f"Unexpected error during SQL execution: {e}. Query: {query}")
        return f"An unexpected error occurred: {str(e)}"


# --- New functions to handle metadata JSON ---
METADATA_PATH = Path(__file__).parent / "assets" / "database_metadata.json"

@st.cache_data
def load_db_metadata(path: Path = METADATA_PATH) -> Optional[Dict]:
    """Loads the database metadata from the specified JSON file."""
    if not path.exists():
        st.error(f"Metadata file not found: {path}")
        logger.error(f"Metadata file not found: {path}")
        return None
    try:
        with open(path, 'r') as f:
            metadata = json.load(f)
        logger.info(f"Successfully loaded database metadata from {path}")
        return metadata
    except json.JSONDecodeError as e:
        st.error(f"Error decoding metadata JSON from {path}: {e}")
        logger.error(f"Error decoding metadata JSON from {path}: {e}")
        return None
    except Exception as e:
        st.error(f"Error loading metadata file {path}: {e}")
        logger.error(f"Error loading metadata file {path}: {e}")
        return None

def format_schema_from_metadata(metadata: Optional[Dict]) -> str:
    """Formats the schema string from loaded metadata for the AI prompt."""
    if not metadata or 'tables' not in metadata:
        return "Error: Could not load or parse database metadata."

    schema_parts = []
    db_desc = metadata.get("description")
    if db_desc:
        schema_parts.append(f"Database Description: {db_desc}")

    for table_name, table_info in metadata.get("tables", {}).items():
        schema_parts.append(f"\nTable: {table_name}")
        table_desc = table_info.get("description")
        if table_desc:
            schema_parts.append(f"  (Description: {table_desc})")

        columns = table_info.get("columns", {})
        if columns:
            for col_name, col_info in columns.items():
                col_type = col_info.get("type", "UNKNOWN")
                col_desc = col_info.get("description", "")
                schema_parts.append(f"  - {col_name} ({col_type}) - {col_desc}")
        else:
            schema_parts.append("  - (No columns found in metadata)")

    if not schema_parts or len(schema_parts) <= 1: # Check if only DB desc was added
        return "No tables found in the database metadata."

    return "\n".join(schema_parts)

# Place this near the other schema formatting functions

def format_schema_for_selected_tables(metadata: Dict, db_key: str, selected_table_names: List[str]) -> str:
    """Formats the schema string for a specific list of tables within a database key."""
    if 'databases' not in metadata or db_key not in metadata['databases']:
        return f"Error: Database key '{db_key}' not found in metadata."

    db_entry = metadata['databases'][db_key]
    schema_parts = []
    db_name = db_entry.get("database_name", db_key)
    # db_desc = db_entry.get("description", "") # Maybe omit top-level desc for pruning focus

    # schema_parts.append(f"Database: {db_name} ({db_key})")
    # if db_desc:
    #     schema_parts.append(f"Description: {db_desc}")

    tables = db_entry.get("tables", {})
    if not tables:
         schema_parts.append(f"\nNo tables found in metadata for database {db_key}.")
         return "\n".join(schema_parts)

    found_tables = False
    for table_name in selected_table_names:
        if table_name in tables:
            found_tables = True
            table_info = tables[table_name]
            schema_parts.append(f"\nTable: {table_name}")
            table_desc = table_info.get("description")
            if table_desc:
                schema_parts.append(f"  (Description: {table_desc})")

            columns = table_info.get("columns", {})
            if columns:
                schema_parts.append("  Columns:") # Explicitly label columns section
                for col_name, col_info in columns.items():
                    col_type = col_info.get("type", "TEXT")
                    col_desc = col_info.get("description", "")
                    col_type_display = col_type if col_type else "TEXT"
                    schema_parts.append(f"    - {col_name} ({col_type_display}) - {col_desc}")
            else:
                schema_parts.append("  - (No columns found in metadata for this table)")
        # else: # Optionally log if a selected table wasn't found in metadata
        #     logger.warning(f"Table '{table_name}' selected by TableAgent not found in metadata for DB '{db_key}'.")


    if not found_tables:
        schema_parts.append(f"\nNone of the selected tables ({', '.join(selected_table_names)}) were found in the metadata for database {db_key}.")

    return "\n".join(schema_parts)

# --- Helper Function to list tables for TableAgent ---
def get_table_descriptions_for_db(metadata: Dict, db_key: str) -> str:
    """Generates a string listing table names and descriptions for the TableAgent."""
    if 'databases' not in metadata or db_key not in metadata['databases']:
        return f"Error: Database key '{db_key}' not found in metadata."

    db_entry = metadata['databases'][db_key]
    tables = db_entry.get("tables", {})
    if not tables:
         return f"No tables found in metadata for database {db_key}."

    desc_parts = [f"Available Tables in Database '{db_entry.get('database_name', db_key)}':"]
    for table_name, table_info in tables.items():
        desc = table_info.get("description", "No description available.")
        desc_parts.append(f"- {table_name}: {desc}")

    return "\n".join(desc_parts)
    
# --- MODIFIED: Function to format schema for a SPECIFIC database ---
def format_schema_for_db(metadata: Dict, db_key: str) -> str:
    """Formats the schema string for a specific database key from loaded metadata."""
    if 'databases' not in metadata or db_key not in metadata['databases']:
        return f"Error: Database key '{db_key}' not found in metadata."

    db_entry = metadata['databases'][db_key]
    schema_parts = []
    db_name = db_entry.get("database_name", db_key)
    db_desc = db_entry.get("description", "")

    schema_parts.append(f"Database: {db_name} ({db_key})")
    if db_desc:
        schema_parts.append(f"Description: {db_desc}")

    tables = db_entry.get("tables", {})
    if not tables:
         schema_parts.append("\nNo tables found in metadata for this database.")
         return "\n".join(schema_parts)

    for table_name, table_info in tables.items():
        schema_parts.append(f"\nTable: {table_name}")
        table_desc = table_info.get("description")
        if table_desc:
            schema_parts.append(f"  (Description: {table_desc})")

        columns = table_info.get("columns", {})
        if columns:
            for col_name, col_info in columns.items():
                col_type = col_info.get("type", "TEXT") # Default to TEXT if missing
                col_desc = col_info.get("description", "")
                # Ensure type is not empty, default again if it somehow is
                col_type_display = col_type if col_type else "TEXT"
                schema_parts.append(f"  - {col_name} ({col_type_display}) - {col_desc}")
        else:
            schema_parts.append("  - (No columns found in metadata for this table)")

    return "\n".join(schema_parts)

# --- NEW: Function to identify target database using LLM ---
async def identify_target_database(
    user_query: str,
    metadata: Dict,
    # No longer pass model, instantiate locally
) -> Tuple[Optional[str], str]:
    """
    Identifies which database (IFC or MIGA) the user query is most likely referring to.
    Returns a tuple (database_key, reasoning) where database_key is None if the query doesn't
    match a specific database.
    """
    logger.info(f"Attempting to identify target database for query: {user_query[:50]}...")
    if 'databases' not in metadata:
        return None, "Error: 'databases' key missing in metadata."

    descriptions = []
    valid_keys = []
    for key, db_info in metadata['databases'].items():
        desc = db_info.get('description', f'Database {key}')
        descriptions.append(f"- {key}: {desc}")
        valid_keys.append(key)

    if not descriptions:
         return None, "Error: No databases found in metadata to classify against."

    descriptions_str = "\n".join(descriptions)
    valid_keys_str = ", ".join([f"'{k}'" for k in valid_keys]) + ", or 'UNKNOWN'"

    classification_prompt = f"""Given the user query and the descriptions of available databases, identify which database the query is most likely related to.

Available Databases:
{descriptions_str}

User Query: "{user_query}"

Based *only* on the query and the database descriptions, which database key ({valid_keys_str}) is the most relevant target? If the query is ambiguous, unrelated to these specific databases, or a general greeting/request (like 'hello', 'thank you'), classify it as 'UNKNOWN'.
"""
    logger.info("--- Sending classification request to LLM ---")
    logger.info(f"Prompt:\n{classification_prompt}")
    logger.info("--------------------------------------------")

    try:
        # Using a temporary Agent for structured output
        # Configure GenAI 
        google_api_key = st.secrets.get("GOOGLE_API_KEY", os.getenv("GOOGLE_API_KEY"))
        genai.configure(api_key=google_api_key)
        
        # Instantiate Model
        gemini_model_name = st.secrets.get("GEMINI_MODEL", "gemini-1.0-pro")
        local_llm = GeminiModel(model_name=gemini_model_name)
        logger.info(f"Instantiated GeminiModel: {gemini_model_name} for classification.")
        
        # Create and run classifier agent
        classifier_agent = Agent(
            local_llm,
            result_type=DatabaseClassification,
            name="Database Classifier",
            system_prompt="You are an AI assistant that classifies user queries based on provided database descriptions. Output ONLY the structured classification result."
        )
        
        # Directly await the coroutine instead of using asyncio.run()
        classification_result = await classifier_agent.run(classification_prompt)

        if hasattr(classification_result, 'data') and isinstance(classification_result.data, DatabaseClassification):
            result_data: DatabaseClassification = classification_result.data
            logger.info(f"--- LLM Classification Result ---")
            logger.info(f"Key: {result_data.database_key}")
            logger.info(f"Reasoning: {result_data.reasoning}")
            logger.info("-------------------------------")
            if result_data.database_key == "UNKNOWN":
                return None, f"Could not determine the target database. Reasoning: {result_data.reasoning}"
            elif result_data.database_key in valid_keys:
                return result_data.database_key, result_data.reasoning
            else:
                 logger.warning(f"LLM returned an invalid key: {result_data.database_key}")
                 return None, f"Classification returned an unexpected key '{result_data.database_key}'. Reasoning: {result_data.reasoning}"
        else:
             logger.error(f"Classification call returned unexpected structure: {classification_result}")
             return None, "Error: Failed to get a valid classification structure from the AI."

    except Exception as e:
        logger.exception("Error during database classification LLM call:")
        return None, f"Error during database classification: {str(e)}"

# --- Optional: Result Validation ---
async def validate_query_result(ctx: RunContext[AgentDependencies], result: QueryResponse) -> QueryResponse:
    """
    Validate the generated response.
    - Checks SQL syntax using EXPLAIN QUERY PLAN.
    - Cleans potential extraneous characters from SQL.
    - Checks if SQL is missing when likely needed.
    - Checks if Python code is missing or declined for visualization requests.
    - Enforces SQL security by blocking potentially harmful statements.
    Raises ModelRetry if validation fails, prompting the LLM to correct the response.
    """
    user_message = ctx.prompt # The message sent to the agent (includes schema and user query)
    logger.info(f"Running result validation for prompt: {user_message[:100]}...")
    logger.debug(f"Validator received result object: {result}") # DEBUG log for full object if needed

    # --- SQL Validation --- #
    if result.sql_result and ctx.deps.db_connection:
        # Clean SQL query - remove potential extraneous backslashes
        original_sql = result.sql_result.sql_query
        cleaned_sql = original_sql.replace('\\', '') # Replace backslashes
        if cleaned_sql != original_sql:
            logger.info(f"Cleaned SQL query. Original: '{original_sql}', Cleaned: '{cleaned_sql}'")
            result.sql_result.sql_query = cleaned_sql # Update the result object
        else:
            cleaned_sql = original_sql # Ensure cleaned_sql is set

        # --- Enhanced Security Validation --- #
        # Check for potentially harmful SQL statements - similar to execute_sql but earlier in the pipeline
        forbidden_commands = ['ALTER', 'CREATE', 'DELETE', 'DROP', 'INSERT', 'UPDATE', 'PRAGMA', 
                           'ATTACH', 'DETACH', 'VACUUM', 'GRANT', 'REVOKE', 'EXECUTE', 'TRUNCATE']
        
        # Normalized query for checking (uppercase without comments)
        normalized_query = ' '.join([
            line for line in cleaned_sql.upper().split('\n') 
            if not line.strip().startswith('--')
        ])
        
        # Check if query is a SELECT statement
        if not normalized_query.strip().startswith("SELECT"):
            logger.warning(f"Non-SELECT query generated: {cleaned_sql}")
            raise ModelRetry("Only SELECT queries are allowed for security reasons. Please regenerate a proper SELECT query.")
        
        # Check for forbidden commands that might be hidden in subqueries or clauses
        for cmd in forbidden_commands:
            if f" {cmd} " in f" {normalized_query} ":
                logger.warning(f"Detected forbidden SQL command '{cmd}' in: {cleaned_sql}")
                raise ModelRetry(f"The SQL query contains a potentially harmful command '{cmd}'. For security reasons, only pure SELECT statements are allowed. Please regenerate the query without this command.")
        
        # Check for multiple statements with semicolons (except those in quotes)
        statement_count = 0
        in_quotes = False
        for char in cleaned_sql:
            if char in ["'", '"']:
                in_quotes = not in_quotes
            if char == ';' and not in_quotes:
                statement_count += 1
        
        if statement_count > 0:
            logger.warning(f"Multiple SQL statements detected: {cleaned_sql}")
            raise ModelRetry("Multiple SQL statements are not allowed for security reasons. Please provide a single SELECT query without semicolons.")

        # Validate SQL Syntax using EXPLAIN QUERY PLAN (suitable for SQLite)
        try:
            cursor = ctx.deps.db_connection.cursor()
            cursor.execute(f"EXPLAIN QUERY PLAN {cleaned_sql}")
            cursor.fetchall()
            logger.info("Generated SQL query syntax validated successfully.")
        except sqlite3.Error as e:
            error_detail = f"SQL Syntax Validation Error: {e}. Query: {cleaned_sql}"
            logger.error(error_detail)
            logger.warning(f"Raising ModelRetry due to SQL Syntax Error. Response details: text='{result.text_message}', sql='{cleaned_sql}'")
            raise ModelRetry(f"The generated SQL query has invalid syntax: {str(e)}. Please correct the SQL query.") from e
        except Exception as e:
             error_detail = f"Unexpected SQL Validation Error: {e}. Query: {cleaned_sql}"
             logger.error(error_detail)
             logger.warning(f"Raising ModelRetry due to Unexpected SQL Error. Response details: text='{result.text_message}', sql='{cleaned_sql}'")
             raise ModelRetry(f"An unexpected error occurred during SQL validation: {str(e)}. Please try generating the SQL query again.") from e

    # --- Check for Missing SQL when Expected --- #
    # Simple keyword check on the original user query part of the prompt
    data_query_keywords = ['total', 'sum', 'average', 'count', 'list', 'show', 'per', 'group', 'compare', 'what is', 'how many']
    # Extract the user's actual question if possible (assuming structure "User Question: ...")
    user_question_marker = "User Question:"
    original_user_question = user_message[user_message.find(user_question_marker):] if user_question_marker in user_message else user_message

    if not result.sql_result and any(keyword in original_user_question.lower() for keyword in data_query_keywords):
        # Check if it's just a clarification or greeting
        is_greeting = any(greet in original_user_question.lower() for greet in ['hello', 'hi', 'thanks', 'thank you'])
        # More robust clarification check - look for question marks or specific keywords
        is_clarification = '?' not in original_user_question and not any(kw in original_user_question.lower() for kw in ['explain', 'what is', 'how does'])

        if not is_greeting and not is_clarification:
            logger.warning(f"SQL result is missing, but keywords {data_query_keywords} suggest it might be needed for query: {original_user_question[:100]}...")
            logger.warning(f"Raising ModelRetry due to Missing SQL. Response details: text='{result.text_message}', sql=None")
            raise ModelRetry("The user's question appears to require data retrieval, but no SQL query was generated. Please generate the appropriate SQL query.")

    # --- Visualization Validation ---
    visualization_keywords = ['chart', 'plot', 'graph', 'visualize', 'visualise', 'visualization', 'visualisation', 'bar chart', 'pie chart', 'histogram', 'line graph']
    decline_phrases = ['cannot plot', 'unable to plot', 'cannot visualize', 'unable to visualize', 'cannot create chart', 'unable to create chart', 'do not have the ability to create plots']
    chart_suggestion_phrases = ["bar chart", "line chart", "pie chart", "scatter plot", "area chart"] # Expected suggestions
    is_visualization_request = any(keyword in original_user_question.lower() for keyword in visualization_keywords)
    has_declined_visualization = any(phrase in result.text_message.lower() for phrase in decline_phrases)
    has_suggested_chart = any(phrase in result.text_message.lower() for phrase in chart_suggestion_phrases)

    if is_visualization_request:
        # Check 1: Did the AI decline?
        if has_declined_visualization:
            logger.warning(f"Visualization requested, but the text response seems to decline the capability for query: {original_user_question[:100]}...")
            logger.warning(f"Raising ModelRetry due to Visualization Declined. Response details: text='{result.text_message}', sql='{result.sql_result.sql_query if result.sql_result else None}'")
            raise ModelRetry("The response incorrectly stated an inability to create visualizations. You MUST suggest an appropriate chart type (e.g., 'bar chart', 'line chart') in your text message and generate the necessary SQL query.")

        # Check 2: Was SQL generated? (Essential for any viz)
        if not result.sql_result:
            logger.warning(f"Visualization requested, but SQL query is missing for query: {original_user_question[:100]}...")
            logger.warning(f"Raising ModelRetry due to Missing SQL for Viz. Response details: text='{result.text_message}', sql=None")
            raise ModelRetry("The user requested a visualization, but the SQL query needed to fetch the data was missing. Please generate the appropriate SQL query and suggest a chart type in your text message.")

        # Check 3: Was a chart type suggested in the text?
        if not has_suggested_chart:
            logger.warning(f"Visualization requested, SQL provided, but no chart type suggested in text for query: {original_user_question[:100]}...")
            logger.warning(f"Raising ModelRetry due to Missing Chart Suggestion. Response details: text='{result.text_message}', sql='{result.sql_result.sql_query if result.sql_result else None}', python='{'present' if result.python_result else 'absent'}'")
            # If Python prep code exists, the AI might think that's enough. Clarify text suggestion is needed.
            if result.python_result:
                 raise ModelRetry("The user requested a visualization, and you provided SQL and Python data preparation code. However, you MUST also explicitly suggest the chart type (e.g., 'bar chart', 'line chart') in your text message.")
            else:
                 raise ModelRetry("The user requested a visualization, and you provided the SQL query. However, you MUST also explicitly suggest the chart type (e.g., 'bar chart', 'line chart') in your text message.")

        # Check 4: If Python code exists, is SQL missing? (Should be caught by Check 2, but good redundancy)
        # This scenario implies Python code was generated perhaps for non-viz reasons, but viz was also requested.
        if result.python_result and not result.sql_result:
             logger.warning(f"Visualization requested and Python code generated, but the necessary SQL query is missing in this response for query: {original_user_question[:100]}...")
             logger.warning(f"Raising ModelRetry due to Missing SQL with Python for Viz. Response details: text='{result.text_message}', sql=None, python='present'")
             raise ModelRetry("The user requested a visualization and Python code was generated, but the SQL query needed to fetch the data was missing from the response. Please provide BOTH the SQL query and suggest a chart type in your text message.")

    # --- Check if Python code depends on SQL results that weren't generated ---
    # (Keeping the original warning logic, but could also be a ModelRetry case)
    if result.python_result and not result.sql_result and not is_visualization_request:
         logger.warning("Python code generated without corresponding SQL query.")
         # Modify explanation instead of retry for now, unless it's clearly broken
         result.text_message += "\nNote: Python code was generated, but no SQL query was provided for this step. The Python code might expect data that isn't available."
         result.python_result.explanation += " Warning: This code might assume data from a previous step or may not run correctly without prior data loading."
         # Alternatively, could raise retry:
         # logger.warning(f"Raising ModelRetry due to Python without SQL. Response details: text='{result.text_message}', sql=None, python='present'")
         # raise ModelRetry("Python code was generated, but it seems to depend on data from a SQL query which was not generated. Please generate the SQL query first, then the Python code.")

    logger.info("Result validation completed successfully.")
    return result # Return the validated (or modified) result

# --- Helper Functions ---
def get_base64_encoded_image(image_path):
    """Get base64 encoded image"""
    try:
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode()
    except FileNotFoundError:
        logger.warning(f"Image file not found: {image_path}")
        return None
    except Exception as e:
        logger.error(f"Error encoding image {image_path}: {str(e)}")
        return None

# --- Main Application Logic ---
async def handle_user_message(message: str) -> None:
    """Handles user input, identifies DB, selects tables, prunes columns, runs the agent, and updates the chat history state."""
    logger.info(f"handle_user_message started for message: {message[:50]}...")
    # Log the user's full message for easier debugging
    logger.info("==== USER QUERY RECEIVED ====")
    logger.info(message)
    logger.info("============================")

    # --- ADDED: Check for follow-up charting request --- #
    follow_up_chart_keywords = ['chart', 'plot', 'graph', 'visualize', 'visualise']
    follow_up_pronouns = ['this', 'that', 'it']
    message_lower = message.lower()
    is_short_message = len(message.split()) <= 5 # Heuristic: short message
    is_follow_up_chart_request = (
        is_short_message and
        any(pronoun in message_lower for pronoun in follow_up_pronouns) and
        any(keyword in message_lower for keyword in follow_up_chart_keywords)
    )

    if is_follow_up_chart_request and st.session_state.get('last_chartable_data') is not None:
        logger.info("Detected follow-up charting request with available data.")
        df_to_chart = st.session_state.last_chartable_data
        db_key = st.session_state.get('last_chartable_db_key', 'Unknown DB')

        # Determine chart type (simple keyword check for now)
        chart_type = None
        if "bar" in message_lower: chart_type = "bar"
        elif "line" in message_lower: chart_type = "line"
        elif "area" in message_lower: chart_type = "area"
        elif "scatter" in message_lower: chart_type = "scatter"
        elif "pie" in message_lower: chart_type = "pie"

        if not chart_type:
            # Basic default or ask? Let's default to bar for now if simple.
            if len(df_to_chart.columns) > 1:
                 chart_type = "bar"
                 logger.warning("Follow-up chart type not specified, defaulting to bar chart.")
            else:
                 # Cannot chart single column easily without more info
                 st.session_state.chat_history.append({
                     "role": "assistant",
                     "content": f"Please specify the type of chart (e.g., bar, line, pie) you want for the previous data from the {db_key} database."
                 })
                 logger.warning("Follow-up chart type not specified, cannot default chart type.")
                 return # Exit early

        # --- Prepare DataFrame for Streamlit Charting (Copied from later logic) --- #
        if chart_type != "pie" and df_to_chart.index.name is None and len(df_to_chart.columns) > 1:
            potential_index_col = df_to_chart.columns[0]
            # Check if the potential index column is suitable (e.g., string/categorical)
            # Using pandas types for better check
            if pd.api.types.is_string_dtype(df_to_chart[potential_index_col]) or \
               pd.api.types.is_categorical_dtype(df_to_chart[potential_index_col]) or \
               pd.api.types.is_datetime64_any_dtype(df_to_chart[potential_index_col]):
                try:
                    logger.info(f"Attempting to automatically set DataFrame index to '{potential_index_col}' for follow-up charting.")
                    # Create a copy before modifying to avoid changing the stored state directly if set_index fails
                    df_display = df_to_chart.copy().set_index(potential_index_col)
                    logger.info("Index set successfully for display.")
                except Exception as e:
                    logger.warning(f"Could not automatically set index for follow-up charting: {e}. Using original DataFrame.")
                    df_display = df_to_chart # Fallback to original df
            else:
                logger.info(f"First column '{potential_index_col}' not suitable for index, using original DataFrame for chart.")
                df_display = df_to_chart
        else:
            df_display = df_to_chart # Use original df if index exists, only one column, or pie chart

        # Construct assistant message with chart
        assistant_chat_message = {
            "role": "assistant",
            "content": f"Okay, here's the {chart_type} chart for the previous data from the {db_key} database:",
            "streamlit_chart": {
                "type": chart_type,
                "data": df_display # Use the potentially indexed dataframe for display
            }
        }
        st.session_state.chat_history.append(assistant_chat_message)
        logger.info("Appended follow-up chart message to history.")
        return # Skip the rest of the pipeline
    # --- END ADDED --- #

    # Ensure we're running in a thread with an event loop
    try:
        asyncio.get_running_loop()
        logger.info("Running event loop found in handle_user_message.")
    except RuntimeError:
        logger.warning("No running event loop detected in handle_user_message, creating one")
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

    deps = None
    assistant_chat_message = None
    agent_run_result = None
    target_db_key = None # Track the identified database
    selected_tables = [] # Track selected tables
    pruned_schema_info = None # Track pruned schema
    pruning_explanation = None # Track pruning reasoning

    # --- Load Metadata (Step 1) ---
    logger.info("Step 1: Loading database metadata...")
    db_metadata = load_db_metadata() # Load metadata using cached function
    if not db_metadata:
        logger.error("Metadata loading failed.")
        st.session_state.chat_history.append({
            "role": "assistant",
            "content": "Sorry, I couldn't load the database configuration. Please check the logs."
        })
        return
    logger.info("Step 1: Database metadata loaded successfully.")

    # Define process_message function - This encapsulates the core logic
    async def process_message_inner(user_query: str):
        nonlocal deps, assistant_chat_message, agent_run_result, target_db_key, selected_tables, pruned_schema_info, pruning_explanation
        logger.info("process_message_inner started.")
        try:
            # --- Identify Target Database (Step 2) ---
            logger.info("Step 2: Identifying target database...")
            identified_key, reasoning = await identify_target_database(user_query, db_metadata)
            logger.info(f"Step 2: Database identification result - Key: {identified_key}, Reasoning: {reasoning}")

            if not identified_key:
                last_key = st.session_state.get('last_db_key')
                if last_key:
                    logger.warning(f"Database identification failed, reusing last key: {last_key}. Original Reasoning: {reasoning}")
                    target_db_key = last_key
                else:
                    logger.warning(f"Database identification failed or returned UNKNOWN. Cannot proceed without target DB. Reasoning: {reasoning}")
                    assistant_chat_message = {
                        "role": "assistant",
                        "content": f"I'm not sure which database to use for your query (IFC or MIGA). Could you please specify? (Reasoning: {reasoning})"
                    }
                    logger.info(f"Assigned assistant message (DB unknown): {assistant_chat_message['content']}")
                    st.session_state.chat_history.append(assistant_chat_message)
                    return # Stop processing here
            else:
                target_db_key = identified_key # Assign the successfully identified key

            logger.info(f"Step 2: Target database confirmed as: {target_db_key}")
            st.session_state.last_db_key = target_db_key

            # --- Get Specific DB Path (Step 3 - Path only, connect later) ---
            logger.info(f"Step 3: Getting database path for key: {target_db_key}...")
            db_entry = db_metadata.get('databases', {}).get(target_db_key)
            if not db_entry or 'database_path' not in db_entry:
                error_msg = f"Metadata configuration error: Could not find path for database '{target_db_key}'."
                logger.error(error_msg)
                st.error(error_msg)
                assistant_chat_message = {"role": "assistant", "content": f"Sorry, internal configuration error for database {target_db_key}."}
                logger.info(f"Assigned assistant message (DB path error): {assistant_chat_message['content']}")
                st.session_state.chat_history.append(assistant_chat_message)
                return # Stop processing here

            target_db_path = db_entry['database_path']
            logger.info(f"Step 3: Database path found: {target_db_path}")

            # --- Table Selection Agent (Step 4) ---
            logger.info(f"Step 4: Running Table Selection Agent for DB: {target_db_key}...")
            table_descriptions = get_table_descriptions_for_db(db_metadata, target_db_key)
            if table_descriptions.startswith("Error:") or table_descriptions.startswith("No tables found"):
                 logger.error(f"Could not get table descriptions for TableAgent: {table_descriptions}")
                 assistant_chat_message = {"role": "assistant", "content": f"Sorry, couldn't retrieve table list for {target_db_key}."}
                 logger.info(f"Assigned assistant message (Table list error): {assistant_chat_message['content']}")
                 st.session_state.chat_history.append(assistant_chat_message)
                 return # Stop processing if table list unavailable

            table_agent_prompt = f"""User Query: "{user_query}"

Database: {target_db_key}
{table_descriptions}

Based on the user query, which of the listed tables are required?
"""
            logger.info("Step 4: Calling Table Selection Agent...")
            try:
                # Configure GenAI
                google_api_key = st.secrets.get("GOOGLE_API_KEY", os.getenv("GOOGLE_API_KEY"))
                genai.configure(api_key=google_api_key)
                
                # Instantiate Model
                gemini_model_name = st.secrets.get("GEMINI_MODEL", "gemini-1.0-pro")
                local_llm = GeminiModel(model_name=gemini_model_name)
                logger.info(f"Instantiated GeminiModel: {gemini_model_name} for table selection.")
                
                # Create and run table selection agent
                agent_instance = create_table_selection_agent(local_llm) # Use blueprint
                table_agent_result = await agent_instance.run(table_agent_prompt)
                
                if hasattr(table_agent_result, 'data') and isinstance(table_agent_result.data, SuggestedTables):
                    selected_tables = table_agent_result.data.table_names
                    logger.info(f"Step 4: Table Agent suggested tables: {selected_tables}. Reasoning: {table_agent_result.data.reasoning}")

                    if not selected_tables:
                        logger.warning("Table Selection Agent returned an empty list of tables.")
                        st.warning(f"Could not identify specific tables needed for your query in the {target_db_key} database. Please refine your query or check table names.")
                        assistant_chat_message = {"role": "assistant", "content": f"I couldn't determine which tables are needed for your query in the {target_db_key} database."}
                        logger.info(f"Assigned assistant message (No tables selected): {assistant_chat_message['content']}")
                        st.session_state.chat_history.append(assistant_chat_message)
                        return # Stop if no tables selected

                    # Get all available tables for this DB
                    db_entry = db_metadata.get('databases', {}).get(target_db_key)
                    all_tables = list(db_entry.get("tables", {}).keys()) if db_entry else []
                    # Store in session state and pause for user confirmation
                    st.session_state.table_confirmation_pending = True
                    st.session_state.candidate_tables = selected_tables
                    st.session_state.all_tables = all_tables
                    st.session_state.table_agent_reasoning = table_agent_result.data.reasoning
                    st.session_state.pending_user_message = user_query
                    st.session_state.pending_db_metadata = db_metadata
                    st.session_state.pending_target_db_key = target_db_key
                    logger.info("Step 4: Pausing for table confirmation.")
                    return  # Pause here until user confirms

                else:
                    # Handle unexpected result structure from Table Agent
                    logger.error(f"Table Selection Agent returned unexpected structure: {table_agent_result}")
                    raise ValueError("Table Selection Agent did not return the expected SuggestedTables structure.")

            except Exception as e:
                logger.exception("Error running Table Selection Agent:")
                st.error(f"Error selecting tables: {e}")
                assistant_chat_message = {"role": "assistant", "content": f"Sorry, I had trouble figuring out which tables to use for the {target_db_key} database."}
                logger.info(f"Assigned assistant message (Table agent error): {assistant_chat_message['content']}")
                st.session_state.chat_history.append(assistant_chat_message)
                return # Stop if table selection fails

            # --- Column Pruning Agent (Step 5) --- #
            logger.info("Step 5: Running Column Pruning Agent...")
            full_schema_for_selected = format_schema_for_selected_tables(db_metadata, target_db_key, selected_tables)
            if full_schema_for_selected.startswith("Error:") or "No tables found" in full_schema_for_selected or "None of the selected tables" in full_schema_for_selected:
                logger.error(f"Could not get full schemas for selected tables: {full_schema_for_selected}")
                assistant_chat_message = {"role": "assistant", "content": f"Sorry, couldn't retrieve schema details for the selected tables in {target_db_key}."}
                logger.info(f"Assigned assistant message (Schema retrieval error): {assistant_chat_message['content']}")
                st.session_state.chat_history.append(assistant_chat_message)
                return # Stop processing if table schema cannot be retrieved

            pruning_agent_prompt = f"""User Query: "{user_query}"

Full Database Schema for Selected Tables:
{full_schema_for_selected}

Analyze the user query and prune this schema to include ONLY the essential columns needed to answer the query.
"""
            try:
                # Configure GenAI
                google_api_key = st.secrets.get("GOOGLE_API_KEY", os.getenv("GOOGLE_API_KEY"))
                genai.configure(api_key=google_api_key)
                
                # Instantiate Model
                gemini_model_name = st.secrets.get("GEMINI_MODEL", "gemini-1.0-pro")
                local_llm = GeminiModel(model_name=gemini_model_name)
                logger.info(f"Instantiated GeminiModel: {gemini_model_name} for column pruning.")
                
                # Create and run column pruning agent
                agent_instance = create_column_prune_agent(local_llm) # Use blueprint
                pruning_result = await agent_instance.run(pruning_agent_prompt)
                
                if hasattr(pruning_result, 'data') and isinstance(pruning_result.data, PrunedSchemaResult):
                    pruned_schema_info = pruning_result.data.pruned_schema_string # Use the pruned schema
                    pruning_explanation = pruning_result.data.explanation
                    logger.info(f"Column Pruning Agent completed. Explanation: {pruning_explanation}")
                    logger.info(f"Pruned Schema:\n{pruned_schema_info}")
                else:
                    logger.error(f"Column Pruning Agent returned unexpected structure: {pruning_result}")
                    raise ValueError("Column Pruning Agent did not return the expected PrunedSchemaResult structure.")
            except Exception as e:
                logger.exception("Error running Column Pruning Agent:")
                st.error(f"Error optimizing schema: {e}")
                logger.warning("Falling back to using the full schema for selected tables due to pruning error.")
                pruned_schema_info = full_schema_for_selected # Fallback to full schema of selected tables
                pruning_explanation = "(Pruning failed, using full schema for selected tables)"
                st.warning("AI failed to prune columns, using full schema for selected tables.", icon="⚠️")

            # --- Connect to DB (Step 6 - Only connect when needed for query_agent/execution) ---
            logger.info(f"Step 6: Connecting to database: {target_db_path} for key: {target_db_key}")
            deps = AgentDependencies.create().with_db(db_path=target_db_path)

            if not deps.db_connection:
                 logger.error(f"Database connection failed for {target_db_path}.")
                 st.error(f"Database connection failed for {target_db_path}. Cannot process request.")
                 assistant_chat_message = {
                     "role": "assistant",
                     "content": f"Sorry, I couldn't connect to the {target_db_key} database..."
                 }
                 logger.info(f"Assigned assistant message (DB connection failed): {assistant_chat_message['content']}")
                 st.session_state.chat_history.append(assistant_chat_message)
                 return

            logger.info("Step 6: Database connection successful.")

            # --- Check schema_info validity before proceeding ---
            if not pruned_schema_info or pruned_schema_info.startswith("Error:") or "No tables found" in pruned_schema_info:
                error_detail = f"Schema information is invalid: {pruned_schema_info}"
                logger.error(error_detail)
                st.error(error_detail) # Display the specific error
                assistant_chat_message = {
                    "role": "assistant",
                    "content": f"Sorry, I encountered an issue preparing the schema for the {target_db_key} database: {pruned_schema_info}"
                }
                logger.info(f"Assigned assistant message (Invalid schema): {assistant_chat_message['content']}")
                st.session_state.chat_history.append(assistant_chat_message)
                if deps: await deps.cleanup()
                return

            # --- Prepare and Run Main Query Agent (Step 7 - Uses PRUNED schema_info) ---
            logger.info("Step 7: Preparing and running Main Query Agent...")
            usage = Usage()

            # --- Token Limit Check (Example - Check before agent call) --- #
            current_total_tokens = getattr(usage, 'total_tokens', 0) or 0
            limit_value = getattr(DEFAULT_USAGE_LIMITS, 'total_tokens_limit', None)
            total_tokens_limit = limit_value if isinstance(limit_value, int) else 1000000
            logger.debug(f"Token check: Current={current_total_tokens}, Limit={total_tokens_limit}")

            if current_total_tokens > total_tokens_limit:
                error_msg = "Token limit exceeded before running the main query agent."
                logger.error(error_msg)
                st.error(error_msg)
                assistant_chat_message = {"role": "assistant", "content": error_msg}
                logger.info(f"Assigned assistant message (Token limit exceeded): {assistant_chat_message['content']}")
                st.session_state.chat_history.append(assistant_chat_message)
                if deps: await deps.cleanup() # Ensure cleanup even on early exit
                return

            try:
                logger.info(f"Step 7: Analyzing request for database '{target_db_key}' with schema and contacting Gemini...")

                history_for_agent = st.session_state.agent_message_history
                logger.info(f"Step 7: Passing cumulative history (length {len(history_for_agent)}) to agent.")

                # Construct the prompt message using the potentially pruned schema_info
                prompt_message = f"""Target Database: {target_db_key}
Database Schema (potentially pruned for relevance):
{pruned_schema_info}

User Request: {user_query}"""

                visualization_keywords = ['chart', 'plot', 'graph', 'visualize', 'visualise', 'visualization', 'visualisation', 'bar chart', 'pie chart', 'histogram', 'line graph']
                is_visualization_request = any(keyword in user_query.lower() for keyword in visualization_keywords)

                if is_visualization_request:
                    logger.info("Step 7: Detected a visualization request - adjusting prompt.")
                    prompt_message += f"""

IMPORTANT: This is a visualization request for the {target_db_key} database.
1. Generate the appropriate SQL query to retrieve the necessary data from the provided schema.
2. In your text response, you MUST suggest an appropriate chart type (e.g., "bar chart", "line chart", "pie chart") based on the user's request and the data.
Do NOT generate Python code for plotting (e.g., using matplotlib or seaborn).
"""
                else:
                    logger.info("Step 7: Standard (non-visualization) request.")

                logger.info("==== AI CALL (Query Agent) ====")
                logger.info(f"Sending prompt message to AI:\n{prompt_message}")
                logger.info("==============================")

                # Use a completely isolated execution instead of sharing event loops
                # Configure GenAI
                google_api_key = st.secrets.get("GOOGLE_API_KEY", os.getenv("GOOGLE_API_KEY"))
                genai.configure(api_key=google_api_key)
                
                # Instantiate Model
                gemini_model_name = st.secrets.get("GEMINI_MODEL", "gemini-1.0-pro")
                local_llm = GeminiModel(model_name=gemini_model_name)
                logger.info(f"Instantiated GeminiModel: {gemini_model_name} for query generation.")
                
                # Create and run query agent
                agent_instance = create_query_agent(local_llm) # Use blueprint
                agent_run_result = await agent_instance.run(
                    prompt_message,
                    deps=deps,
                    usage=usage,
                    usage_limits=DEFAULT_USAGE_LIMITS,
                    message_history=history_for_agent # Pass the history
                )
                
                logger.info(f"Step 7: Query Agent call completed. Result type: {type(agent_run_result)}")
                # Log token usage if available
                usage_obj = None
                try:
                    usage_attr = getattr(agent_run_result, 'usage', None)
                    if callable(usage_attr):
                        usage_obj = usage_attr()
                    else:
                        usage_obj = usage_attr
                    if usage_obj is not None:
                        logger.info(f"Token Usage (this call): {agent_run_result.usage.prompt_tokens} prompt, {usage_obj.completion_tokens} completion, {usage_obj.total_tokens} total.")
                    else:
                        logger.info("Token Usage (this call): Usage information not available.")
                except Exception as e:
                    logger.warning(f"Could not log token usage: {e}")
                st.session_state.last_result = agent_run_result # Store for potential debug
                logger.info("Stored agent run result in session state.")

                # Append new messages to cumulative history
                if hasattr(agent_run_result, 'new_messages'):
                    new_msgs = agent_run_result.new_messages()
                    st.session_state.agent_message_history.extend(new_msgs)
                    logger.info(f"Appended {len(new_msgs)} new messages to agent_message_history (new total: {len(st.session_state.agent_message_history)}). ")
                else:
                     logger.warning("Agent result object does not have 'new_messages' attribute.")


                # --- Process Query Agent Response (Step 8) ---
                logger.info("Step 8: Processing Query Agent response...")
                if hasattr(agent_run_result, 'data') and isinstance(agent_run_result.data, QueryResponse):
                    response: QueryResponse = agent_run_result.data
                    logger.info("Step 8: Agent response has expected QueryResponse structure.")

                    # Log the response from the AI
                    logger.info("==== AI RESPONSE (Query Agent) ====")
                    logger.info(f"Text message: {response.text_message}")
                    if response.sql_result:
                        logger.info(f"SQL query: {response.sql_result.sql_query}")
                        logger.info(f"SQL explanation: {response.sql_result.explanation}")
                    else:
                        logger.info("SQL query: None")
                    if response.python_result:
                        logger.info(f"Python code explanation: {response.python_result.explanation}")
                        logger.info(f"Python code snippet:\n{response.python_result.python_code}")
                    else:
                        logger.info("Python code: None")
                    logger.info("===================================")

                    # Construct the base assistant message
                    assistant_chat_message = {"role": "assistant", "content": f"[{target_db_key} database] {response.text_message}"}
                    logger.info(f"Assigned base assistant message: {assistant_chat_message['content']}")

                    sql_results_df = None
                    if response.sql_result:
                        logger.info(f"Step 8a: Executing SQL query against {target_db_key} database...")
                        logger.info(f"SQL to execute: {response.sql_result.sql_query}")
                        sql_run_context = RunContext(
                            deps=deps, # Use the existing deps
                            model=llm, # Reuse the model
                            usage=usage, # Reuse usage object
                            prompt=response.sql_result.sql_query # Prompt context for tool
                        )
                        sql_execution_result = await execute_sql(sql_run_context, response.sql_result.sql_query)

                        sql_info = {
                            "query": response.sql_result.sql_query,
                            "explanation": response.sql_result.explanation
                        }
                        if isinstance(sql_execution_result, str): # Error
                            sql_info["error"] = sql_execution_result
                            logger.error(f"SQL execution failed: {sql_execution_result}")
                        elif isinstance(sql_execution_result, list):
                            if sql_execution_result:
                                logger.info(f"SQL execution successful, {len(sql_execution_result)} rows returned.")
                                sql_results_df = pd.DataFrame(sql_execution_result)
                                sql_info["results"] = sql_results_df.to_dict('records')
                                sql_info["columns"] = list(sql_results_df.columns)
                                # --- ADDED: Store successful results for potential follow-up --- #
                                st.session_state.last_chartable_data = sql_results_df
                                st.session_state.last_chartable_db_key = target_db_key
                                logger.info(f"Stored chartable data (shape: {sql_results_df.shape}) and db_key ({target_db_key}) in session state.")
                                # --- END ADDED --- #
                            else:
                                logger.info("SQL execution successful, 0 rows returned.")
                                sql_info["results"] = [] # Empty results
                                sql_results_df = pd.DataFrame() # Ensure df is an empty DataFrame
                        else:
                             sql_info["error"] = "Unexpected result type from SQL execution."
                             logger.error(f"{sql_info['error']} Type: {type(sql_execution_result)}")
                             sql_results_df = pd.DataFrame() # Ensure df is an empty DataFrame on unexpected error

                        assistant_chat_message["sql_result"] = sql_info
                        logger.info("Added sql_result block to assistant message.")

                    # Initialize df_for_chart with the SQL results (or empty if failed/no results)
                    df_for_chart = sql_results_df if sql_results_df is not None else pd.DataFrame()
                    chart_type = None # Initialize chart type

                    if response.python_result:
                        logger.info("Step 8b: Executing Python data preparation code...")
                        python_info = {
                            "code": response.python_result.python_code,
                            "explanation": response.python_result.explanation
                        }
                        python_code = response.python_result.python_code
                        logger.info(f"Python code to execute:\n{python_code}")

                        # Prepare local variables for exec, including the DataFrame from SQL
                        local_vars = {
                            'pd': pd,
                            'np': np,
                            'st': st, # Keep st in case it's used for non-plotting things
                            'df': df_for_chart.copy() # Pass a copy to avoid modifying the original outside exec scope
                        }

                        try:
                            exec(python_code, globals(), local_vars)
                            # Retrieve the potentially modified DataFrame from local_vars
                            df_for_chart = local_vars['df']
                            logger.info("Python data preparation code executed successfully.")
                            if isinstance(df_for_chart, pd.DataFrame):
                                logger.info(f"DataFrame shape after Python code: {df_for_chart.shape}")
                            else:
                                logger.warning(f"'df' variable after Python code is not a DataFrame, type: {type(df_for_chart)}")
                        except Exception as e:
                            logger.error(f"Error executing Python data preparation code: {e}\nCode:\n{python_code}", exc_info=True)
                            python_info["error"] = str(e)

                        assistant_chat_message["python_result"] = python_info
                        logger.info("Added python_result block to assistant message.")

                    # --- Determine Chart Type from AI Response (Step 8c) --- #
                    logger.info("Step 8c: Determining chart type...")
                    if df_for_chart is not None and not df_for_chart.empty:
                        text_lower = response.text_message.lower()
                        # More specific checks for chart type phrases
                        if "bar chart" in text_lower: chart_type = "bar"
                        elif "line chart" in text_lower: chart_type = "line"
                        elif "area chart" in text_lower: chart_type = "area"
                        elif "scatter plot" in text_lower or "scatter chart" in text_lower: chart_type = "scatter"
                        elif "pie chart" in text_lower: chart_type = "pie"

                        if chart_type:
                            logger.info(f"Detected chart type: {chart_type}")
                            # --- Prepare DataFrame for Streamlit Charting (Example: Set Index) --- #
                            if df_for_chart.index.name is None and len(df_for_chart.columns) > 1:
                                potential_index_col = df_for_chart.columns[0]
                                if pd.api.types.is_string_dtype(df_for_chart[potential_index_col]):
                                    try:
                                         logger.info(f"Attempting to automatically set DataFrame index to '{potential_index_col}' for charting.")
                                         df_for_chart = df_for_chart.set_index(potential_index_col)
                                         logger.info("Index set successfully.")
                                    except Exception as e:
                                         logger.warning(f"Could not automatically set index for charting: {e}")

                            # Store chart type and data for display function
                            assistant_chat_message["streamlit_chart"] = {
                                "type": chart_type,
                                "data": df_for_chart # Store the potentially modified dataframe
                            }
                            logger.info(f"Added streamlit_chart block (type: {chart_type}) to assistant message.")
                        else:
                            logger.info("No specific chart type detected in AI response.")
                    else:
                         logger.info("DataFrame is empty or None, skipping chart generation check.")

                    logger.info("Step 8: Query Agent response processing complete.")

                else:
                     # Handle case where agent result is not the expected QueryResponse
                     error_msg = "Received an unexpected response structure from main Query Agent."
                     logger.error(f"{error_msg} Raw RunResult type: {type(agent_run_result)}, Content: {agent_run_result}")
                     st.error(error_msg)
                     assistant_chat_message = {"role": "assistant", "content": f"Sorry, internal issue processing the {target_db_key} database query results..."}
                     logger.info(f"Assigned assistant message (Query agent response structure error): {assistant_chat_message['content']}")

            except ModelRetry as mr:
                # Handle validation errors specifically if needed
                error_msg = f"Query Agent validation failed: {str(mr)}"
                logger.error(error_msg, exc_info=True) # Log the retry reason
                st.error(error_msg)
                assistant_chat_message = {"role": "assistant", "content": f"Sorry, I encountered a validation issue while processing the request for {target_db_key}: {str(mr)}"}
                logger.info(f"Assigned assistant message (ModelRetry): {assistant_chat_message['content']}")
            except Exception as e:
                error_msg = f"An error occurred during main query agent processing: {str(e)}"
                logger.exception("Error during main query agent execution or response processing:")
                st.error(error_msg)
                assistant_chat_message = {"role": "assistant", "content": f"Sorry, I encountered an error generating the response for the {target_db_key} database: {str(e)}"}
                logger.info(f"Assigned assistant message (Query agent exception): {assistant_chat_message['content']}")

        except Exception as e:
            # Catch-all for errors during the inner process setup (before main agent call)
            error_msg = f"A critical error occurred during message processing setup: {str(e)}"
            logger.exception("Critical error in process_message_inner setup:")
            st.error(error_msg)
            # Ensure assistant_chat_message is set if an error occurs early
            if not assistant_chat_message:
                 assistant_chat_message = {"role": "assistant", "content": f"Sorry, a critical error occurred: {str(e)}"}
                 logger.info(f"Assigned assistant message (Critical setup error): {assistant_chat_message['content']}")

        finally:
            # --- Cleanup and Final Message Handling (Step 9) ---
            logger.info("Step 9: Entering finally block of process_message_inner.")
            if assistant_chat_message:
                # Check if the message is already in history (e.g., added during early exit)
                # This prevents duplicate error messages if an error happened AND set assistant_chat_message before finally
                is_duplicate = False
                if st.session_state.chat_history:
                    last_msg = st.session_state.chat_history[-1]
                    if last_msg.get("role") == "assistant" and last_msg.get("content") == assistant_chat_message.get("content"):
                         is_duplicate = True
                         logger.info("Duplicate assistant message detected, skipping append.")

                if not is_duplicate:
                    st.session_state.chat_history.append(assistant_chat_message)
                    logger.info(f"Assistant message appended to history in finally block. Content: {assistant_chat_message.get('content')}")
            else:
                 # This case should ideally not happen if errors are handled properly
                 logger.error("process_message_inner finished without generating an assistant message object.")
                 # Append a generic error message if nothing else was generated
                 if not st.session_state.chat_history or not (st.session_state.chat_history[-1]['role'] == 'assistant'):
                      st.session_state.chat_history.append({"role": "assistant", "content": "Sorry, an internal error occurred, and no response could be generated."})
                      logger.info("Appended generic error message as no specific assistant message was set.")

            if deps:
                logger.info("Step 9: Cleaning up database connection.")
                await deps.cleanup()
            logger.info("process_message_inner finished.")

    # Call the inner processing function
    await process_message_inner(message)

    logger.info(f"handle_user_message finished for message: {message[:50]}...")
    # --- End of handle_user_message ---


# --- New async function: continue_after_table_confirmation ---
async def continue_after_table_confirmation():
    logger.info("continue_after_table_confirmation called.")
    # Retrieve what we need from session state
    db_metadata = st.session_state.get("pending_db_metadata")
    target_db_key = st.session_state.get("pending_target_db_key")
    message = st.session_state.get("pending_user_message")
    selected_tables = st.session_state.get("confirmed_tables", [])
    logger.info(f"Continuing with DB: {target_db_key}, Tables: {selected_tables}, Query: {message[:50]}...")

    # --- Define a single async function to run subsequent agents --- #
    async def run_agents_post_confirmation_inner():
        deps = None
        # --- REMOVED prune agent related variables ---
        # pruned_schema_info = None
        # pruning_explanation = None
        final_assistant_message_dict = None # To store the result

        try:
            # --- Instantiate Model and Agents Locally (once for this flow) --- #
            google_api_key = st.secrets.get("GOOGLE_API_KEY", os.getenv("GOOGLE_API_KEY"))
            try:
                genai.configure(api_key=google_api_key)
                logger.info("Configured GenAI SDK within post-confirmation flow.")
            except Exception as config_err:
                 logger.error(f"Failed to configure GenAI SDK: {config_err}")
                 return f"Internal Error: Failed to configure AI Service ({config_err})."

            gemini_model_name = st.secrets.get("GEMINI_MODEL", "gemini-1.0-pro")
            local_llm = GeminiModel(model_name=gemini_model_name)
            logger.info(f"Locally instantiated GeminiModel: {gemini_model_name} for post-confirmation flow.")
            # --- REMOVED prune agent instantiation ---
            # local_prune_agent = create_column_prune_agent(local_llm)
            local_query_agent = create_query_agent(local_llm)
            # --- End Instantiation --- #

            # --- REMOVED Column Pruning Agent Step --- #
            # logger.info(f"Running Column Pruning Agent for CONFIRMED tables: {selected_tables}...")
            full_schema_for_selected = format_schema_for_selected_tables(db_metadata, target_db_key, selected_tables)
            if full_schema_for_selected.startswith("Error:") or "No tables found" in full_schema_for_selected or "None of the selected tables" in full_schema_for_selected:
                logger.error(f"Could not get full schemas for selected tables: {full_schema_for_selected}")
                st.error(f"Could not get full schemas for selected tables: {full_schema_for_selected}")
                return f"Sorry, couldn't retrieve schema details for the selected tables in {target_db_key}."
            logger.info("Using full schema for selected tables (pruning step skipped).")
            schema_to_use = full_schema_for_selected # Use the full schema

            # --- Connect to DB --- #
            # ... (DB connection logic remains the same) ...
            db_entry = db_metadata.get('databases', {}).get(target_db_key)
            target_db_path = db_entry['database_path'] if db_entry and 'database_path' in db_entry else None
            if not target_db_path:
                 logger.error(f"DB Path not found for {target_db_key}")
                 st.error(f"DB Path not found for {target_db_key}")
                 return f"Sorry, internal configuration error finding DB path for {target_db_key}."

            logger.info(f"Connecting to database: {target_db_path} for key: {target_db_key}")
            deps = AgentDependencies.create().with_db(db_path=target_db_path)
            if not deps.db_connection:
                logger.error(f"Database connection failed for {target_db_path}.")
                st.error(f"Database connection failed for {target_db_path}.")
                return f"Sorry, I couldn't connect to the {target_db_key} database..."
            logger.info("Database connection successful.")

            # --- Check schema validity before proceeding --- #
            # Check the schema_to_use variable instead of pruned_schema_info
            if not schema_to_use or schema_to_use.startswith("Error:") or "No tables found" in schema_to_use:
                error_detail = f"Schema information is invalid: {schema_to_use}"
                logger.error(error_detail)
                st.error(error_detail)
                if deps: await deps.cleanup()
                return f"Sorry, I encountered an issue preparing the schema for the {target_db_key} database: {schema_to_use}"

            # --- Prepare and Run Main Query Agent --- #
            # ... (Token check logic remains the same) ...
            logger.info("Preparing and running Main Query Agent (within post-confirmation flow)...")
            usage = Usage()
            current_total_tokens = getattr(usage, 'total_tokens', 0) or 0
            limit_value = getattr(DEFAULT_USAGE_LIMITS, 'total_tokens_limit', None)
            total_tokens_limit = limit_value if isinstance(limit_value, int) else 1000000
            if current_total_tokens > total_tokens_limit:
                error_msg = "Token limit exceeded before running the main query agent."
                logger.error(error_msg)
                st.error(error_msg)
                if deps: await deps.cleanup()
                return error_msg

            try:
                logger.info(f"Analyzing request for database '{target_db_key}' with schema and contacting Gemini...")
                history_for_agent = st.session_state.agent_message_history
                # Use schema_to_use (full schema) in the prompt
                prompt_message = f"""Target Database: {target_db_key}
Database Schema (Full schema for selected tables):
{schema_to_use}

User Request: {message}"""
                # ... (Visualization prompt adjustment logic remains the same) ...
                visualization_keywords = ['chart', 'plot', 'graph', 'visualize', 'visualise', 'visualization', 'visualisation', 'bar chart', 'pie chart', 'histogram', 'line graph']
                is_visualization_request = any(keyword in message.lower() for keyword in visualization_keywords)
                if is_visualization_request:
                    logger.info("Detected a visualization request - adjusting prompt.")
                    prompt_message += f"""

IMPORTANT: This is a visualization request for the {target_db_key} database.
1. Generate the appropriate SQL query to retrieve the necessary data from the provided schema.
2. In your text response, you MUST suggest an appropriate chart type (e.g., \"bar chart\", \"line chart\", \"pie chart\") based on the user's request and the data.
Do NOT generate Python code for plotting (e.g., using matplotlib or seaborn).
"""
                else:
                    logger.info("Standard (non-visualization) request.")

                logger.info("==== AI CALL (Query Agent, post-confirmation) ====")
                logger.info(f"Sending prompt message to AI:\\n{prompt_message}")
                logger.info("==============================")

                # Run query agent
                agent_run_result = await local_query_agent.run(
                    prompt_message,
                    deps=deps,
                    usage=usage,
                    usage_limits=DEFAULT_USAGE_LIMITS,
                    message_history=history_for_agent
                )

                # ... (Rest of the response processing, cleanup, and return logic remains the same) ...
                # Log token usage
                usage_obj = None
                try:
                    usage_attr = getattr(agent_run_result, 'usage', None)
                    if callable(usage_attr): usage_obj = usage_attr()
                    else: usage_obj = usage_attr
                    if usage_obj is not None: logger.info(f"Token Usage (this call): {usage_obj.prompt_tokens} prompt, {usage_obj.completion_tokens} completion, {usage_obj.total_tokens} total.")
                    else: logger.info("Token Usage (this call): Usage information not available.")
                except Exception as e: logger.warning(f"Could not log token usage: {e}")

                st.session_state.last_result = agent_run_result # Store for potential debug
                if hasattr(agent_run_result, 'new_messages'):
                    new_msgs = agent_run_result.new_messages()
                    st.session_state.agent_message_history.extend(new_msgs)
                    logger.info(f"Appended {len(new_msgs)} new messages to agent_message_history.")
                else: logger.warning("Agent result object does not have 'new_messages' attribute.")

                # --- Process Query Agent Response --- #
                logger.info("Processing Query Agent response (after confirmation)...")
                if hasattr(agent_run_result, 'data') and isinstance(agent_run_result.data, QueryResponse):
                    response: QueryResponse = agent_run_result.data
                    logger.info("Agent response has expected QueryResponse structure.")
                    logger.info(f"Text message: {response.text_message}")
                    # Construct the base assistant message
                    base_assistant_message = {"role": "assistant", "content": f"[{target_db_key} database] {response.text_message}"}

                    sql_results_df = None
                    if response.sql_result:
                        logger.info(f"SQL query: {response.sql_result.sql_query}")
                        logger.info(f"SQL explanation: {response.sql_result.explanation}")
                        logger.info(f"Executing SQL query against {target_db_key} database...")
                        sql_run_context = RunContext(deps=deps, model=local_llm, usage=usage, prompt=response.sql_result.sql_query)
                        sql_execution_result = await execute_sql(sql_run_context, response.sql_result.sql_query)
                        sql_info = {"query": response.sql_result.sql_query, "explanation": response.sql_result.explanation}
                        if isinstance(sql_execution_result, str): # Error
                            sql_info["error"] = sql_execution_result
                            logger.error(f"SQL execution failed: {sql_execution_result}")
                        elif isinstance(sql_execution_result, list):
                            if sql_execution_result:
                                logger.info(f"SQL execution successful, {len(sql_execution_result)} rows returned.")
                                sql_results_df = pd.DataFrame(sql_execution_result)
                                sql_info["results"] = sql_results_df.to_dict('records')
                                sql_info["columns"] = list(sql_results_df.columns)
                                # Store successful results
                                st.session_state.last_chartable_data = sql_results_df
                                st.session_state.last_chartable_db_key = target_db_key
                                logger.info(f"Stored chartable data (shape: {sql_results_df.shape}) and db_key ({target_db_key}) in session state (after confirmation).")
                            else:
                                logger.info("SQL execution successful, 0 rows returned.")
                                sql_info["results"] = []
                                sql_results_df = pd.DataFrame()
                        else:
                             sql_info["error"] = "Unexpected result type from SQL execution."
                             sql_results_df = pd.DataFrame()
                        base_assistant_message["sql_result"] = sql_info
                    else:
                        logger.info("SQL query: None")

                    df_for_chart = sql_results_df if sql_results_df is not None else pd.DataFrame()
                    chart_type = None

                    if response.python_result:
                        logger.info(f"Python code explanation: {response.python_result.explanation}")
                        logger.info(f"Python code snippet:\\n{response.python_result.python_code}")
                        python_info = {"code": response.python_result.python_code, "explanation": response.python_result.explanation}
                        python_code = response.python_result.python_code
                        local_vars = {'pd': pd, 'np': np, 'st': st, 'df': df_for_chart.copy()}
                        try:
                            exec(python_code, globals(), local_vars)
                            df_for_chart = local_vars['df']
                            logger.info(f"Python data preparation executed. DataFrame shape: {df_for_chart.shape}")
                        except Exception as e:
                            logger.error(f"Error executing Python data preparation code: {e}", exc_info=True)
                            python_info["error"] = str(e)
                        base_assistant_message["python_result"] = python_info
                    else:
                        logger.info("Python code: None")

                    # Determine Chart Type
                    if df_for_chart is not None and not df_for_chart.empty:
                        text_lower = response.text_message.lower()
                        if "bar chart" in text_lower: chart_type = "bar"
                        elif "line chart" in text_lower: chart_type = "line"
                        elif "area chart" in text_lower: chart_type = "area"
                        elif "scatter plot" in text_lower or "scatter chart" in text_lower: chart_type = "scatter"
                        elif "pie chart" in text_lower: chart_type = "pie"

                        if chart_type:
                            logger.info(f"Detected chart type: {chart_type}")
                            # Prepare DataFrame index for charting
                            if chart_type != "pie" and df_for_chart.index.name is None and len(df_for_chart.columns) > 1:
                                potential_index_col = df_for_chart.columns[0]
                                if pd.api.types.is_string_dtype(df_for_chart[potential_index_col]) or \
                                   pd.api.types.is_categorical_dtype(df_for_chart[potential_index_col]) or \
                                   pd.api.types.is_datetime64_any_dtype(df_for_chart[potential_index_col]):
                                    try:
                                        logger.info(f"Setting index to '{potential_index_col}' for charting.")
                                        df_for_chart = df_for_chart.set_index(potential_index_col)
                                    except Exception as e: logger.warning(f"Could not set index for charting: {e}")
                            base_assistant_message["streamlit_chart"] = {"type": chart_type, "data": df_for_chart}
                            logger.info(f"Added streamlit_chart block (type: {chart_type})")
                        else:
                             logger.info("No specific chart type detected in AI response.")
                    else:
                         logger.info("DataFrame is empty or None, skipping chart generation check.")

                    final_assistant_message_dict = base_assistant_message # Store the complete message dict

                else:
                     error_msg = "Received an unexpected response structure from main Query Agent (after confirmation)."
                     logger.error(f"{error_msg} Type: {type(agent_run_result)}")
                     st.error(error_msg)
                     final_assistant_message_dict = {"role": "assistant", "content": f"Sorry, internal issue processing {target_db_key} results..."}

            except ModelRetry as mr:
                error_msg = f"Query Agent validation failed: {str(mr)}"
                logger.error(error_msg, exc_info=True)
                st.error(error_msg)
                final_assistant_message_dict = {"role": "assistant", "content": f"Sorry, validation issue for {target_db_key}: {str(mr)}"}
            except Exception as e:
                error_msg = f"Error during main query agent processing: {str(e)}"
                logger.exception("Error during query agent or response processing (post-confirmation):")
                st.error(error_msg)
                final_assistant_message_dict = {"role": "assistant", "content": f"Sorry, error generating response for {target_db_key}: {str(e)}"}

        except Exception as e:
            # Catch-all for errors during the inner process setup
            error_msg = f"A critical error occurred during post-confirmation processing setup: {str(e)}"
            logger.exception("Critical error in run_agents_post_confirmation_inner setup:")
            st.error(error_msg)
            if not final_assistant_message_dict:
                 return f"Sorry, a critical error occurred: {str(e)}"

        finally:
            # Cleanup DB connection
            if deps:
                logger.info("Cleaning up database connection from run_agents_post_confirmation_inner.")
                await deps.cleanup()

        return final_assistant_message_dict

    # --- Now, run the consolidated async function --- #
    # ... (The rest of continue_after_table_confirmation remains the same) ...
    assistant_chat_message = None # Reset before run
    try:
        # Directly await the inner async function
        with st.spinner("Processing your confirmed table selection..."):
            result = await run_agents_post_confirmation_inner()

        # Check the result: dictionary means success, string means error message
        if isinstance(result, dict):
            assistant_chat_message = result
            logger.info("run_agents_post_confirmation_inner completed successfully, returning message dict.")
        elif isinstance(result, str):
             # An error occurred, and the inner function returned an error message string
             logger.error(f"run_agents_post_confirmation_inner returned an error message: {result}")
             # Create a standard assistant error message structure
             assistant_chat_message = {"role": "assistant", "content": result}
        else:
             # Should not happen if inner function always returns dict or str on error
             logger.error("run_agents_post_confirmation_inner returned an unexpected type.")
             assistant_chat_message = {"role": "assistant", "content": "Sorry, an unexpected internal error occurred during processing."}

    except Exception as e:
        # Catch errors from asyncio.run() itself or unexpected errors within the inner function
        error_msg = f"A critical error occurred running the post-confirmation agents: {str(e)}"
        logger.exception("Critical error in continue_after_table_confirmation during asyncio.run:")
        st.error(error_msg)
        # Set a generic error message if one wasn't already created
        if not assistant_chat_message:
            assistant_chat_message = {"role": "assistant", "content": f"Sorry, a critical error occurred: {str(e)}"}

    # --- Append the final message to history --- #
    # ... (Appending logic remains the same) ...
    if assistant_chat_message:
        # Simple check to avoid adding duplicate error messages if already added by st.error + st.rerun logic
        is_duplicate = False
        if st.session_state.chat_history:
            last_msg = st.session_state.chat_history[-1]
            if last_msg.get("role") == "assistant" and last_msg.get("content") == assistant_chat_message.get("content"):
                is_duplicate = True
                logger.info("Duplicate assistant message detected, skipping append.")
        if not is_duplicate:
            st.session_state.chat_history.append(assistant_chat_message)
            logger.info(f"Assistant message appended to history in continue_after_table_confirmation. Content: {assistant_chat_message.get('content')[:100]}...")
    else:
        # Fallback if something went wrong and no message was created
        logger.error("continue_after_table_confirmation finished without an assistant message.")
        if not st.session_state.chat_history or not (st.session_state.chat_history[-1]['role'] == 'assistant'):
             st.session_state.chat_history.append({"role": "assistant", "content": "Sorry, an internal error occurred, and no response could be generated."})

    # --- Clean up pending state --- #
    # ... (Cleanup logic remains the same) ...
    keys_to_clear = [
        "pending_db_metadata", "pending_target_db_key", "pending_user_message",
        "confirmed_tables", "candidate_tables", "all_tables", "table_agent_reasoning"
    ]
    for key in keys_to_clear:
        if key in st.session_state:
            del st.session_state[key]
    logger.info("Cleaned up pending session state after confirmation.")

    logger.info("continue_after_table_confirmation finished.")

# --- REMOVED Original logic --- #
# (The rest of the original function's code, which contained separate try/except blocks and agent calls, is removed)

# Move main() function outside handle_user_message to the global scope
def main():
    """Main function to run the Streamlit application."""

    # Initialize session state variables
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = [] # For display
    if 'last_result' not in st.session_state: # Retained for now, might be removable later
        st.session_state.last_result = None
        logger.info("Initialized last_result in session state.")
    if 'last_db_key' not in st.session_state:
        st.session_state.last_db_key = None
        logger.info("Initialized last_db_key in session state.")
    if 'agent_message_history' not in st.session_state: # ADDED: Initialize cumulative history
        st.session_state.agent_message_history = []
        logger.info("Initialized agent_message_history in session state.")
    # --- ADDED: Initialize state for follow-up charting --- #
    if 'last_chartable_data' not in st.session_state:
        st.session_state.last_chartable_data = None
        logger.info("Initialized last_chartable_data in session state.")
    if 'last_chartable_db_key' not in st.session_state:
        st.session_state.last_chartable_db_key = None
        logger.info("Initialized last_chartable_db_key in session state.")
    # --- END ADDED --- #

    # --- Main Page Content ---
    # --- Main Page Content ---
    st.markdown('<h1 style="text-align: center;"><span style="color: #00ade4;">SmartQuery</span></h1>', unsafe_allow_html=True)
    st.markdown("<h5 style='text-align: center; color: #555;'>AI-Powered Database Analysis with Google Gemini</h5>", unsafe_allow_html=True)

    # --- CSS Styles ---
    st.markdown("""
    <style>
        /* Main chat container adjustments */
        .main-chat-container {
            flex-grow: 1; /* Allow chat to take available space */
            display: flex;
            flex-direction: column;
            height: calc(20vh - 250px); /* Adjust height based on surrounding elements */
            overflow: hidden; /* Hide main container overflow */
            margin-top: 0.5rem; /* Reduce top margin from 1rem to 0.5rem */
        }
        /* Make message container scrollable */
        .chat-messages-container {
            flex-grow: 1;
            overflow-y: auto; /* Enable vertical scrolling */
            padding: 0 1rem 0.5rem 1rem; /* Reduce bottom padding from 1rem to 0.5rem */
            margin-bottom: 60px; /* Reduce space for the input box from 70px to 60px */
        }
        /* Sticky input - default Streamlit behavior is usually good */
        /* .stChatInputContainer */

        /* Feature boxes */
        .features-container { display: flex; flex-direction: column; gap: 0.75rem; margin: 0.5rem auto; max-width: 1000px; } /* Reduced margin from 1rem to 0.5rem */
        .features-row { display: flex; justify-content: center; gap: 1.5rem; flex-wrap: wrap; /* Allow wrapping on smaller screens */ }
        .feature-text { flex: 1 1 300px; /* Flex grow, shrink, basis */ max-width: 450px; padding: 1rem; background: #f0f8ff; border: 1px solid #e0e0e0; border-radius: 8px; font-size: .9rem; line-height: 1.4; display: flex; align-items: flex-start; gap: 0.75rem; box-shadow: 0 1px 3px rgba(0,0,0,0.05); }
        .check-icon { width: 18px; height: 18px; object-fit: contain; margin-top: 0.15rem; flex-shrink: 0; }

        /* Example queries */
        .example-queries { margin: 1rem 0 0.75rem 0; font-size: 1rem; border-left: 3px solid #00ade4; padding-left: 1rem; } /* Reduced top margin from 1.5rem to 1rem, bottom from 1rem to 0.75rem */
        .example-queries p { margin-bottom: 0.5rem; font-weight: bold; color: #002345; }
        .example-queries ul { margin: 0; padding-left: 1.2rem; list-style-type: '→ '; }
        .example-queries li { margin-bottom: 0.3rem; color: #333; font-size: 0.9em; }

        /* DataFrame display */
        .stDataFrame { width: 100%; font-size: 0.9em; }

        /* Improve chat message appearance */
        .stChatMessage { border-radius: 10px; border: 1px solid #eee; box-shadow: 0 1px 2px rgba(0,0,0,0.05); margin-top: 0.25rem; } /* Added smaller top margin */
        /* Adjust code block styling */
        .stCodeBlock { font-size: 0.85em; }

    </style>
    """, unsafe_allow_html=True)

    # --- Feature Highlights ---
    # Adjusted path for single file structure
    check_path = Path(__file__).parent / "assets" / "correct.png"
    check_base64 = get_base64_encoded_image(check_path)
    check_img = f'<img src="data:image/png;base64,{check_base64}" class="check-icon" alt="✓">' if check_base64 else "✓"

    st.markdown(f"""
    <div class="features-container">
        <div class="features-row">
            <div class="feature-text">{check_img} Ask natural language questions about IFC or MIGA data.</div>
            <div class="feature-text">{check_img} Get instant SQL-powered insights from both databases.</div>
        </div>
        <div class="features-row">
            <div class="feature-text">{check_img} Generate visualizations (bar, line, pie charts) via Python.</div>
            <div class="feature-text">{check_img} System automatically identifies the right database for your query.</div>
        </div>
    </div>
    """, unsafe_allow_html=True)
    st.info('Query data from the IFC Investment or MIGA Guarantees databases. The AI will identify the appropriate database automatically.', icon=":material/info:")
    # --- Example Queries ---
    st.markdown("""
    <div class="example-queries">
        <p>Example Questions:</p>
        <ul>
            <li>"Visualize the distribution of IFC product lines using a pie chart."</li>
            <li>"Show me MIGA guarantees in the Financial sector from Cambodia."</li>
            <li>"Compare the average IFC investment size for 'Loan' products between Nepal and Bhutan."</li>
            <li>"What is the total gross guarantee exposure for MIGA in the Tourism sector in Senegal?"</li>
            <li>"Which countries have the highest total MIGA guarantee exposure? Create a bar chart."</li>
            <li>"Give me the top 10 IFC equity investments from China"</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)

        # Clear Chat Button (moved from sidebar)
    if st.button("Clear Chat History", key="clear_chat"):
        st.session_state.chat_history = []
        # st.session_state.conversation_context = [] # Unused
        st.session_state.last_result = None
        st.session_state.last_db_key = None
        st.session_state.agent_message_history = [] # ADDED: Reset cumulative history
        # --- ADDED: Reset chartable data on clear --- #
        st.session_state.last_chartable_data = None
        st.session_state.last_chartable_db_key = None
        # --- END ADDED --- #
        logger.info("Chat history, last_result, last_db_key, agent_message_history, and chartable data cleared.")
        st.rerun()

    # --- ADDED: Handle table confirmation continuation asynchronously --- #
    if "confirmed_tables" in st.session_state and not st.session_state.get("table_confirmation_pending", False):
        logger.info("Detected confirmed tables, proceeding with continue_after_table_confirmation...")
        
        # Create an async handler using Streamlit's experimental_reruns
        async def handle_confirmation():
            with st.spinner("Processing your confirmed table selection..."):
                try:
                    await continue_after_table_confirmation()
                    # Cleanup handled within continue_after_table_confirmation
                    logger.info("Continuation after table confirmation complete.")
                    # Clear the confirmed_tables to prevent reprocessing
                    if "confirmed_tables" in st.session_state:
                        del st.session_state.confirmed_tables
                    return True  # Indicate success
                except Exception as e:
                    logger.exception(f"Error in continue_after_table_confirmation: {e}")
                    st.error(f"Error processing your selection: {str(e)}")
                    if "confirmed_tables" in st.session_state:
                        del st.session_state.confirmed_tables
                    return False
        
        # Use run_async helper instead of asyncio.run
        try:
            result = run_async(handle_confirmation())
            if result:
                st.rerun()
            else:
                # Error already handled inside handle_confirmation
                st.rerun()
        except Exception as e:
            logger.exception(f"Error in run_async of confirmation handling: {e}")
            st.error(f"An error occurred: {str(e)}")
            st.rerun()

    # --- Chat Interface --- #
    st.markdown('<div class="main-chat-container">', unsafe_allow_html=True)
    st.markdown('<div class="chat-messages-container">', unsafe_allow_html=True)

    # Chat display container - Renders based on current chat_history
    chat_display_container = st.container()
    with chat_display_container:
        # Display chat history loop
        for i, message in enumerate(st.session_state.chat_history):
            role = message.get("role", "assistant")
            content = message.get("content", "")
            with st.chat_message(role):
                st.markdown(content)
                
                # Display SQL results if present
                sql_result = message.get("sql_result")
                if sql_result:
                    st.markdown("**SQL Query:**")
                    st.code(sql_result.get("query", ""), language="sql")
                    
                    if "explanation" in sql_result and sql_result["explanation"]:
                        st.markdown(f"**Explanation:** {sql_result['explanation']}")
                    
                    if "error" in sql_result:
                        st.error(f"SQL Error: {sql_result['error']}")
                    elif "results" in sql_result and sql_result["results"]:
                        st.markdown("**Results:**")
                        try:
                            results_df = pd.DataFrame(sql_result["results"])
                            st.dataframe(results_df)
                        except Exception as e:
                            st.error(f"Error displaying results: {str(e)}")
                
                # Display Python results if present
                python_result = message.get("python_result")
                if python_result:
                    st.markdown("**Python Code:**")
                    st.code(python_result.get("code", ""), language="python")
                    
                    if "explanation" in python_result and python_result["explanation"]:
                        st.markdown(f"**Explanation:** {python_result['explanation']}")
                    
                    if "error" in python_result:
                        st.error(f"Error executing Python code: {python_result['error']}")

                # Display visualization if available (Moved outside python_result check)
                if "streamlit_chart" in message:
                    st.markdown("**Visualization:**")
                    try:
                        chart_type = message["streamlit_chart"]["type"]
                        df = message["streamlit_chart"]["data"]
                        if chart_type == "bar":
                            st.bar_chart(df)
                        elif chart_type == "line":
                            st.line_chart(df)
                        elif chart_type == "area":
                            st.area_chart(df)
                        elif chart_type == "scatter":
                            # Make sure columns are specified for scatter
                            if len(df.columns) >= 2:
                                st.scatter_chart(df, x=df.columns[0], y=df.columns[1])
                            else:
                                st.warning("Scatter plot requires at least two data columns.")
                        # --- ADDED PIE CHART HANDLING WITH PLOTLY --- #
                        elif chart_type == "pie":
                            if not df.empty and len(df.columns) > 0:
                                # Assuming index = names, first column = values
                                fig = px.pie(df, names=df.index, values=df.columns[0], title="Pie Chart")
                                st.plotly_chart(fig, use_container_width=True)
                            else:
                                st.warning("Cannot generate pie chart: Data is empty or missing columns.")
                        # --- END PIE CHART HANDLING ---
                    except Exception as e:
                        st.error(f"Error displaying visualization: {str(e)}")
        
        # --- ADDED: Display Table Confirmation UI AS A CHAT MESSAGE --- #
        if st.session_state.get("table_confirmation_pending", False):
            logger.info("Rendering table confirmation UI inside chat message area.")
            candidate_tables = st.session_state.get("candidate_tables", [])
            all_tables = st.session_state.get("all_tables", [])
            reasoning = st.session_state.get("table_agent_reasoning", "")
            db_key = st.session_state.get("pending_target_db_key", "")
            
            # Render confirmation as assistant message
            with st.chat_message("assistant"):
                st.info(f"**Table Selection Required:** I suggest using these tables for your query: {', '.join(candidate_tables)}", icon="ℹ️")
                if reasoning:
                    st.caption(f"Reasoning: {reasoning}")
                
                selected = st.multiselect(
                    f"Confirm or adjust tables for your query in the {db_key} database:",
                    options=all_tables,
                    default=candidate_tables,
                    key="table_confirm_multiselect"
                )
                
                if st.button("Confirm Table Selection"):
                    logger.info(f"User confirmed table selection: {selected}")
                    # Just update state and rerun. The logic at the start of main() will handle calling the continuation function.
                    st.session_state.table_confirmation_pending = False
                    st.session_state.confirmed_tables = selected
                    st.rerun() # Trigger rerun to process the confirmation

    # Close chat messages container
    st.markdown('</div>', unsafe_allow_html=True)

    # --- User Input / Table Confirmation --- #
    # Check if table confirmation is pending
    if st.session_state.get("table_confirmation_pending", False):
        # Hide the chat input when table confirmation is pending (already rendered in chat)
        # Empty placeholder to prevent displaying the regular chat input
        st.empty()
    else:
        # --- User Input (only show if confirmation is NOT pending) --- #
        user_input = st.chat_input("Ask about IFC or MIGA data...")

        # --- Handle Input --- #
        if user_input:
            logger.info(f"User input received in main(): {user_input}")

            # Add user message to chat history immediately
            st.session_state.chat_history.append({"role": "user", "content": user_input})

            # Define async handler for user message
            async def process_user_input(input_text):
                try:
                    with st.spinner("Thinking..."):
                        logger.info("Processing user input asynchronously...")
                        await handle_user_message(input_text)
                        logger.info("handle_user_message completed successfully")
                    return True
                except Exception as e:
                    logger.exception(f"Error processing user input: {e}")
                    st.error(f"An error occurred while processing your request: {e}")
                    # Append error to history state if handle_user_message failed critically
                    if not st.session_state.chat_history or not (st.session_state.chat_history[-1]['role'] == 'assistant' and 'critical error' in st.session_state.chat_history[-1]['content']):
                        st.session_state.chat_history.append({"role": "assistant", "content": f"Sorry, a critical error occurred: {e}"})
                        logger.info("Appended critical error message from main() exception block.")
                    return False

            # Use run_async helper instead of asyncio.run
            try:
                result = run_async(process_user_input(user_input))
                if result:
                    st.rerun()
                else:
                    # Error already handled inside process_user_input
                    st.rerun()
            except Exception as e:
                logger.exception(f"Error in run_async of user input processing: {e}")
                st.error(f"An error occurred: {str(e)}")
                st.rerun()

    # Close the main chat container div at the end
    st.markdown('</div>', unsafe_allow_html=True)

        # logger.info("Input processed, script run finishing.") # This might not be reached after rerun

    # # --- ADDED: Additional scroll to bottom at end of main function --- #
    # if st.session_state.get("table_confirmation_pending", False):
    #     # Add another scroll attempt at the end of the main function
    #     from streamlit.components.v1 import html
    #     html("""
    #     <script>
    #         // Final attempt to scroll to the bottom after everything is rendered
    #         function finalScrollAttempt() {
    #             window.scrollTo(0, document.body.scrollHeight);
                
    #             // Try to find the confirmation UI
    #             const confirmButton = document.querySelector('button:contains("Confirm Table Selection")');
    #             if (confirmButton) {
    #                 confirmButton.scrollIntoView(false);
    #             }
                
    #             // Look for our anchor
    #             const anchor = document.getElementById('table_confirmation_anchor');
    #             if (anchor) {
    #                 anchor.scrollIntoView(false);
    #             }
    #         }
            
    #         // Try with delays of increasing length
    #         setTimeout(finalScrollAttempt, 200);
    #         setTimeout(finalScrollAttempt, 700);
    #         setTimeout(finalScrollAttempt, 1200);
    #     </script>
    #     """, height=0, width=0)
    # # --- END additional scroll ---

    # logger.info("Input processed, script run finishing.") # This might not be reached after rerun


if __name__ == "__main__":
    # Set up global asyncio configuration
    try:
        # Apply nest_asyncio for nested event loops
        import nest_asyncio
        nest_asyncio.apply()
        logger.info("Applied nest_asyncio globally")
        
        # Set Windows event loop policy if needed
        if os.name == 'nt':  # Check if OS is Windows
            asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
            logger.info("Set WindowsSelectorEventLoopPolicy for Windows.")
    except Exception as e:
        logger.warning(f"Could not set up asyncio configuration: {e}")
    
    # Run the main function
    main()